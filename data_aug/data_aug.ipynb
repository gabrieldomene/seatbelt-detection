{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imgaug as ia\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load random image from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_content = os.listdir(\"dataset/\")\n",
    "image_list = [img for img in dir_content if img.endswith(\".png\")]\n",
    "file_list = [txt for txt in dir_content if txt.endswith(\".txt\")]\n",
    "image = imageio.imread(\"dataset/{}\".format(random.choice(image_list)))\n",
    "# ia.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment the image\n",
    "`imgaug` can perform different techniques, first augmentation will be  `Affine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented with affine:\n"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "ia.seed(4)\n",
    "\n",
    "rotate = iaa.Affine(rotate=(-25, 25))\n",
    "image_aug = rotate(image=image)\n",
    "\n",
    "print(\"Augmented with affine:\")\n",
    "# ia.imshow(image_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment a batch of images\n",
    "Changing the image param it's possible to achieve augmentation of N numbers of image, the example is\n",
    "made with the same image different times.\n",
    "\n",
    "* hstack() is used to combine the images into one larger for better display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented batch:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "images = [image, image, image, image]\n",
    "images_aug = rotate(images=images)\n",
    "\n",
    "print(\"Augmented batch:\")\n",
    "# ia.imshow(np.hstack(images_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use many augmentation techniques simultaneously\n",
    "\n",
    "The next example we will combine several methods and apply them simultaneously to images. First, we instantiate\n",
    "each technique on its own and apply them one after the other by calling `augmenter(images=...)` several times. Alternatively we can use `Sequential` to combine different augmenters into one pipeline and then apply them all in a single augmentation call. We will use `Affine`, some gaussian noise `AdditiveGaussianNoise` and crop the image randomly with `Crop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-25, 25)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(5, 10)),\n",
    "    iaa.Crop(percent=(0, 0.2))\n",
    "])\n",
    "\n",
    "images_aug = seq(images=images)\n",
    "\n",
    "print(\"Sequential augmented:\")\n",
    "# ia.imshow(np.hstack(images_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sequential with random order\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-25, 25)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(5, 20)),\n",
    "    iaa.Crop(percent=(0, 0.2))\n",
    "], random_order=True)\n",
    "\n",
    "images_aug = [seq(image=image) for _ in range(8)]\n",
    "\n",
    "print(\"Random augmented:\")\n",
    "# ia.imshow(ia.draw_grid(images_aug, cols=4, rows=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting images of different sizes\n",
    "Load batch of different sizes, apply the augmentation as a single batch and show each image one by one with the input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.CropAndPad(percent=(-0.2, 0.2), pad_mode=\"edge\"),#crop and pad img\n",
    "    iaa.AddToHueAndSaturation((-50, 50)), #change color\n",
    "    iaa.ElasticTransformation(alpha=90, sigma=9), #water effect\n",
    "    iaa.Cutout() #replace one squared area within the image by a constant value\n",
    "], random_order=True)\n",
    "\n",
    "images_with_different_sizes = [imageio.imread(\"dataset/{}\".format(img)) for img in random.sample(image_list, 1)]\n",
    "\n",
    "#Augment them as one batch\n",
    "images_aug = seq(images=images_with_different_sizes)\n",
    "\n",
    "for idx, img in enumerate(images_aug):\n",
    "    print(\"Image {} (input shape: {}, output shape: {})\".format(idx, images_with_different_sizes[idx].shape, images_aug[idx].shape))\n",
    "    ia.imshow(np.hstack([images_with_different_sizes[idx], img]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset augmentation \n",
    "\n",
    "### Finished\n",
    "\n",
    "yolo mark format: object-class x y width height\n",
    "\n",
    "* `x` `y` `width` `height` are value within ranges 0-1 relative to the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imgaug as ia\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_coord(file, img):\n",
    "    \"\"\"\n",
    "    Main function for reading the annotation file for the respective image.\n",
    "    \n",
    "    The yolo annotations are stored in a same name .txt file for the mirror .png image, inside the file\n",
    "    the coordinates are stores as a class_name, x, y, width, height relative values of image. The first one\n",
    "    is not used but the last four are stored in variables for later calculations.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    file (file): The .txt file annotation\n",
    "    img (ndarray): The image loaded\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    bbs (imgaug object): The BoundingBoxesOnImage object containing all the coordinates annotated in the\n",
    "    original .txt file.\n",
    "    \"\"\"\n",
    "    with open(\"dataset/{}\".format(file), \"r\") as file:\n",
    "        temp_boundingbox_array = []\n",
    "        for line in file.readlines():\n",
    "            _, relative_x, relative_y, relative_width_box, relative_height_box = line.split(\" \")\n",
    "            print(\"x:{} y:{} HEIGHT:{} WIDTH:{}\".format(relative_x, relative_y, \\\n",
    "                                                        relative_width_box, relative_height_box))\n",
    "\n",
    "            center_y, center_x, real_width_box, real_height_box, y_1, x_1 = calculate_coord(img.shape, \n",
    "                                                                                            relative_x,\n",
    "                                                                                          relative_y,\n",
    "                                                                                          relative_width_box,\n",
    "                                                                                          relative_height_box)\n",
    "\n",
    "            bbs = BoundingBoxesOnImage([\n",
    "                BoundingBox(x1=x_1, x2=(x_1+real_width_box), y1=y_1, y2=(y_1+real_height_box))\n",
    "            ], shape=img.shape)\n",
    "            x_2 = (x_1+real_width_box)\n",
    "            y_2 = (y_1+real_height_box)\n",
    "            temp_boundingbox_array.append([x_1, y_1, x_2, y_2])\n",
    "        \n",
    "    np_boundingbox = np.vstack(temp_boundingbox_array)\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(np_boundingbox, img.shape)\n",
    "    return bbs\n",
    "        \n",
    "def calculate_coord(shape, x, y, width, height):\n",
    "    \"\"\"\n",
    "    Function responsible for calculating the coord values from yolo mark to top-left(x,y) position.\n",
    "    \n",
    "    Since the annotations in yolo format are based in relative positions, this function is responsible\n",
    "    for converting them to the normal top-left format so it can be possible to work with imgaug library\n",
    "    and his bounding boxes.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    shape (tuple): The actual shape of the image which is being used\n",
    "    x (float): Relative X value found in the yolo annotation\n",
    "    y (float): Relative Y value found in the yolo annotation\n",
    "    width (float): Relative WIDTH value found in the yolo annotation\n",
    "    height (float): Relative HEIGHT value found in the yolo annoation\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    abs_y: int value mapped of center Y of bounding box element\n",
    "    abs_x: int value mapped of center X of bounding box element\n",
    "    abs_w: int value mapped of the width size box\n",
    "    abs_h: int value mapped of the height size box\n",
    "    y_1: int value mapped of the top-left Y1\n",
    "    x_2: int value mapped of the top-left X1\n",
    "    \"\"\"\n",
    "    y_image = shape[0]\n",
    "    x_image = shape[1]\n",
    "    \n",
    "    abs_w = int(float(width) * x_image)\n",
    "    abs_h = int(float(height) * y_image)\n",
    "    abs_y = int(float(y) * y_image)\n",
    "    abs_x = int(float(x) * x_image)\n",
    "    \n",
    "    x_1 = int(abs_x - abs_w/2)\n",
    "    y_1 = int(abs_y - abs_h/2)\n",
    "    \n",
    "    \n",
    "    return abs_y, abs_x, abs_h, abs_w, y_1, x_1\n",
    "\n",
    "def save_aug(file, img):\n",
    "    \"\"\"\n",
    "    Save method for the new augmentated images.\n",
    "    \n",
    "    As new augments are generated for the dataset, this function is the one who will save the new pair of\n",
    "    .png and .txt files to the disk.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    file (file): The .txt file annotation\n",
    "    img (ndarray): The image loaded\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    None\n",
    "    \"\"\"\n",
    "    new_image_name = \"{:05d}.png\".format(count)\n",
    "    new_file_name = \"{:05d}.txt\".format(count)\n",
    "    with open(\"dataset/{}\".format(file), \"r\") as old_file:\n",
    "        content = old_file.readlines()\n",
    "    with open(\"dataset/{}\".format(new_file_name), \"w\") as file:\n",
    "        for line in content:\n",
    "            file.write(line)\n",
    "    cv2.imwrite(\"dataset/{}\".format(new_image_name), img)\n",
    "    print(\"Saving {} with {} annotation\" .format(new_image_name, new_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data augmentation in the dataset, 3 methods are chosen in the sequential constructor who will\n",
    "be applied in random order to the batch loaded and saved in the desired folder.\n",
    "\"\"\"\n",
    "\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.AddToHueAndSaturation((-25, 50), per_channel=True),\n",
    "    iaa.MultiplyHueAndSaturation((0.5, 1.5), per_channel=True),\n",
    "    iaa.AddToBrightness((0, 50))\n",
    "], random_order=True)\n",
    "count = 0\n",
    "random.shuffle(image_list)\n",
    "for _ in range(5):\n",
    "    for idx, img in enumerate(image_list):\n",
    "        current_image = img\n",
    "        current_annotation = current_image.replace(\".png\", \".txt\")\n",
    "        print(\"Image name: {}, respective annotation: {}\\n\\n\" .format(current_image, current_annotation))\n",
    "        image = imageio.imread(\"dataset/{}\".format(current_image))\n",
    "        bbs = read_coord(current_annotation, image)\n",
    "        image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
    "        save_aug(current_annotation, image_aug)\n",
    "        count += 1\n",
    "#         ia.imshow(np.hstack([bbs.draw_on_image(image, size=4), bbs_aug.draw_on_image(image_aug, size=3)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
